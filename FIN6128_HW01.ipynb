{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you begin, learn to write equations under Jupyter Markdown mode\n",
    "\n",
    "First, under \"help\" tab, click \"Keyboard Shortcuts\" to view shortcut operations, or click \"Markdown\" to view how to edit markdown cells.\n",
    "\n",
    "To switch between \"Markdown\" mode or \"code\" mode, click a cell you want to change, then under the tool tab (which is right above this cell) click the dropdown option which is to the left of the \"keyboard\" icon. \n",
    "\n",
    "Click Ctrl + Enter to run any cell in any mode.\n",
    "\n",
    "In jupyter you can write equations with Latex format. Simply type equations between two signs \"$\".\n",
    "\n",
    "Double click the cell to view the source code. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I Basics: Broadcasting and sigmoid function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Broadcasting\n",
    "\n",
    "Broadcasting in NumPy follows a strict set of rules to determine the interaction between the two arrays:\n",
    "\n",
    "* Rule 1: If the two arrays differ in their number of dimensions, the shape of the one with fewer dimensions is padded with ones on its leading (left) side.\n",
    "* Rule 2: If the shape of the two arrays does not match in any dimension, the array with shape equal to 1 in that dimension is stretched to match the other shape.\n",
    "* Rule 3: If in any dimension the sizes disagree and neither is equal to 1, an error is raised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([0, 1, 2])\n",
    "b = np.array([5, 5, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 6, 7])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If arrays are of same size, element to element operation takes place\n",
    "* Because of broadcasting, scaler value 5 is converted into vector & ops takes place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 6, 7])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([ [1,2,3], [4,5,6] ])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6,  7,  8],\n",
       "       [ 9, 10, 11]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/awantik/PythonDataScienceHandbook/raw/f2c4a8af3f6e7e5f455469839e31b09ab6c22868/notebooks/figures/02.05-broadcasting.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(3).reshape(3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [2]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.arange(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [1, 2, 3],\n",
       "       [2, 3, 4]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets initiate a matrix M and a vector a. Notice that the length of the vector a has to match the last dimension of M (or the dimension 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.ones((2, 3))\n",
    "a = np.arange(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 3),\n",
       " array([[1., 1., 1.],\n",
       "        [1., 1., 1.]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.shape, M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [1., 2., 3.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M + a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [1., 2., 3.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2,3],[4,5,6]])\n",
    "b = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will this work? why?\n",
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "won't work  \n",
    "\n",
    "ValueError: operands could not be broadcast together with shapes (2,3) (3,3)   \n",
    "\n",
    "The operation `a + b` will not work due to shape incompatibility.  \n",
    "\n",
    "Here's why:  \n",
    "- Shape of `a`: (2, 3) (2 rows × 3 columns)\n",
    "- Shape of `b`: (3, 3) (3 rows × 3 columns)  \n",
    "\n",
    "When performing element-wise operations (like addition) in NumPy, arrays must follow broadcasting rules.  \n",
    "\n",
    "The key broadcasting rules are:\n",
    "- Dimensions must match exactly.\n",
    "- One (or both) dimension(s) must have size 1.  \n",
    "  \n",
    "In this case:  \n",
    "\n",
    "- The second dimension (columns) matches (3 vs. 3).\n",
    "- The first dimension (rows) has sizes 2 and 3, which are incompatible (neither is 1).  \n",
    "\n",
    "As a result, NumPy cannot broadcast the arrays to a compatible shape. The operation will raise a ValueError indicating that the operands could not be broadcast together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.reshape(1,2,3)\n",
    "b = b.reshape(3,1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[1, 2, 3],\n",
       "         [4, 5, 6]]]),\n",
       " array([[[1, 2, 3]],\n",
       " \n",
       "        [[4, 5, 6]],\n",
       " \n",
       "        [[7, 8, 9]]]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 2,  4,  6],\n",
       "        [ 5,  7,  9]],\n",
       "\n",
       "       [[ 5,  7,  9],\n",
       "        [ 8, 10, 12]],\n",
       "\n",
       "       [[ 8, 10, 12],\n",
       "        [11, 13, 15]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# will this work? why?\n",
    "\n",
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes. It works.  \n",
    "\n",
    "The operation `a + b` works because of NumPy's broadcasting rules.\n",
    "\n",
    "1. **Shape of `a`**: (1, 2, 3)\n",
    "2. **Shape of `b`**: (3, 1, 3)\n",
    "\n",
    "Broadcasting allows the dimensions to be compatible by:\n",
    "- **Third dimension** (size 3): Both arrays have this size, so no adjustment needed.\n",
    "- **Second dimension** (size 1 in `b` and size 2 in `a`): The dimension of size `1` can be broadcast to `2`.\n",
    "- **First dimension** (size 1 in `a` and size 3 in `b`): The dimension of size `1` can be broadcast to `3`.\n",
    "\n",
    "After broadcasting, both arrays are expanded to shape **(3, 2, 3)**, enabling element-wise addition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Practice time !!**\n",
    "\n",
    "First let M be a zero matrix of size 4 * 3, $a$ be an array of size (3, ) with elements ranging from 0 to 2, $b$ be an array of size (4, ) with elements ranging from 1 to 4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.zeros((4,3))\n",
    "\n",
    "a = np.arange(3)\n",
    "b = np.arange(1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "零矩阵 M 是：\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "\n",
      "数组 a 是：\n",
      "[0 1 2]\n",
      "\n",
      "数组 b 是：\n",
      "[1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "print(\"零矩阵 M 是：\")\n",
    "print(M)\n",
    "print(\"\\n数组 a 是：\")\n",
    "print(a)\n",
    "print(\"\\n数组 b 是：\")\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's add $a$ to each row of M and assign the resulting matrix to N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = M + a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "矩阵 N 是：\n",
      "[[0. 1. 2.]\n",
      " [0. 1. 2.]\n",
      " [0. 1. 2.]\n",
      " [0. 1. 2.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n矩阵 N 是：\")\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, add $b$ to each column of N using broadcast. There are multiple ways to do it. You can try np.newaxis or reshape. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "N2 = N + b[ : , np.newaxis]\n",
    "N3 = N + b.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "矩阵 N2 是：\n",
      "[[1. 2. 3.]\n",
      " [2. 3. 4.]\n",
      " [3. 4. 5.]\n",
      " [4. 5. 6.]]\n",
      "\n",
      "矩阵 N3 是：\n",
      "[[1. 2. 3.]\n",
      " [2. 3. 4.]\n",
      " [3. 4. 5.]\n",
      " [4. 5. 6.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n矩阵 N2 是：\")\n",
    "print(N2)\n",
    "print(\"\\n矩阵 N3 是：\")\n",
    "print(N3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid function and np.exp() function\n",
    "\n",
    "\n",
    "**Reminder**:\n",
    "$sigmoid(x) = \\frac{1}{1+e^{-x}}$ is sometimes also known as the logistic function. It is a non-linear function used not only in Machine Learning (Logistic Regression), but also in Deep Learning.\n",
    "\n",
    "<img src=\"images/Sigmoid.png\" style=\"width:500px;height:228px;\">\n",
    "\n",
    "To refer to a function belonging to a specific package you could call it using package_name.function(). Run the code below to see an example with math.exp()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Implement the sigmoid function and its derivative using numpy. \n",
    "\n",
    "**Instructions**: When you call a function, say exponential on an array, numpy allows for element-wise operation over the whole array.\n",
    "$$ \\text{For } x \\in \\mathbb{R}^n \\text{,     } sigmoid(x) = sigmoid\\begin{pmatrix}\n",
    "    x_1  \\\\\n",
    "    x_2  \\\\\n",
    "    ...  \\\\\n",
    "    x_n  \\\\\n",
    "\\end{pmatrix} = \\begin{pmatrix}\n",
    "    \\frac{1}{1+e^{-x_1}}  \\\\\n",
    "    \\frac{1}{1+e^{-x_2}}  \\\\\n",
    "    ...  \\\\\n",
    "    \\frac{1}{1+e^{-x_n}}  \\\\\n",
    "\\end{pmatrix}\\tag{1} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this\n",
    "\n",
    "a = np.random.rand(3) # This initiate an random arry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.11498385, 1.21349362, 1.66362706])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.exp(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrtie your code for sigmoid here\n",
    "\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Compute the sigmoid of x\n",
    "\n",
    "    Arguments:\n",
    "    x -- A scalar or numpy array of any size\n",
    "\n",
    "    Return:\n",
    "    s -- sigmoid(x)\n",
    "    \"\"\"\n",
    "    s = 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Excercise** Define a class named My_Sigmoid Within the class, define two methods forward and backward. The forward method will take an input array $x$ and calculate its sigmoid transformation. The backward will calculate the derivative of sigmoid function at $x$\n",
    "\n",
    "**Instruction** The formula is: $$sigmoid\\_derivative(x) = \\sigma'(x) = \\sigma(x) (1 - \\sigma(x))\\tag{2}$$\n",
    "You often code this function in two steps:\n",
    "1. Set s to be the sigmoid of x. You might find your sigmoid(x) function useful.\n",
    "2. Compute $\\sigma'(x) = s(1-s)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_Sigmoid:\n",
    "    '''\n",
    "    forward: compute the sigmoid(x) given x, x can be a list or a numpy array or a value, if x is a list, then perform element \n",
    "    wise transformation.\n",
    "    \n",
    "    backward: compute the derivative of sigmoid(x), using the fomula above\n",
    "    \n",
    "    '''\n",
    "    def __init__(self, x):\n",
    "        if x is None:\n",
    "            self.y= 0\n",
    "            self.dy = 0\n",
    "        else:\n",
    "            x = np.array(x)\n",
    "            self.y = 1/(np.exp(-x) + 1)\n",
    "            self.dy = self.y*(1-self.y)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = np.array(x)\n",
    "        #######one line code here#######\n",
    "        self.y = 1 / (1 + np.exp(-x))\n",
    "        return self.y\n",
    "    \n",
    "    def backward(self, x):\n",
    "        x = np.array(x)\n",
    "        #######one line code here#######\n",
    "        self.y = 1 / (1 + np.exp(-x))\n",
    "        #######one line code here#######\n",
    "        self.dy = self.y * (1 - self.y)\n",
    "        \n",
    "        \n",
    "        return self.dy\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.99954602e-01 4.53978687e-05 5.00000000e-01 8.80797078e-01]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4.53958077e-05, 4.53958077e-05, 2.50000000e-01, 1.04993585e-01])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test:\n",
    "mysigmoid= My_Sigmoid(x = None)\n",
    "\n",
    "mysigmoid.forward([10, -10, 0, 2])\n",
    "print(mysigmoid.y)\n",
    "mysigmoid.backward([10, -10, 0, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping arrays\n",
    "\n",
    "Two common numpy functions used in deep learning are [np.shape](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.shape.html) and [np.reshape()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html). \n",
    "- X.shape is used to get the shape (dimension) of a matrix/vector X. \n",
    "- X.reshape(...) is used to reshape X into some other dimension. \n",
    "\n",
    "For example, in computer science, an image is represented by a 3D array of shape $(length, height, depth = 3)$. However, when you read an image as the input of an algorithm you convert it to a vector of shape $(length*height*3, 1)$. In other words, you \"unroll\", or reshape, the 3D array into a 1D vector.\n",
    "\n",
    "*Credit for the picture: Andrew Ng Deep Learning*\n",
    "\n",
    "<img src=\"images/image2vector_kiank.png\" style=\"width:500px;height:300;\">\n",
    "\n",
    "**Exercise**: Implement `image2vector()` that takes an input of shape (length, height, 3) and returns a vector of shape (length\\*height\\*3, 1). For example, if you would like to reshape an array v of shape (a, b, c) into a vector of shape (a*b,c) you would do:\n",
    "``` python\n",
    "v = v.reshape((v.shape[0]*v.shape[1], v.shape[2])) # v.shape[0] = a ; v.shape[1] = b ; v.shape[2] = c\n",
    "```\n",
    "- Please don't hardcode the dimensions of image as a constant. Instead look up the quantities you need with `image.shape[0]`, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: image2vector\n",
    "def image2vector(image):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    image -- a numpy array of shape (length, height, depth)\n",
    "    \n",
    "    Returns:\n",
    "    v -- a vector of shape (length*height*depth, 1)\n",
    "    \"\"\"\n",
    "    v = image.reshape((image.shape[0] * image.shape[1] * image.shape[2], 1))\n",
    "    \n",
    "    return v\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image2vector(image) = [[0.67826139]\n",
      " [0.29380381]\n",
      " [0.90714982]\n",
      " [0.52835647]\n",
      " [0.4215251 ]\n",
      " [0.45017551]\n",
      " [0.92814219]\n",
      " [0.96677647]\n",
      " [0.85304703]\n",
      " [0.52351845]\n",
      " [0.19981397]\n",
      " [0.27417313]\n",
      " [0.60659855]\n",
      " [0.00533165]\n",
      " [0.10820313]\n",
      " [0.49978937]\n",
      " [0.34144279]\n",
      " [0.94630077]]\n"
     ]
    }
   ],
   "source": [
    "# This is a 3 by 3 by 2 array, typically images will be (num_px_x, num_px_y,3) where 3 represents the RGB values\n",
    "image = np.array([[[ 0.67826139,  0.29380381],\n",
    "        [ 0.90714982,  0.52835647],\n",
    "        [ 0.4215251 ,  0.45017551]],\n",
    "\n",
    "       [[ 0.92814219,  0.96677647],\n",
    "        [ 0.85304703,  0.52351845],\n",
    "        [ 0.19981397,  0.27417313]],\n",
    "\n",
    "       [[ 0.60659855,  0.00533165],\n",
    "        [ 0.10820313,  0.49978937],\n",
    "        [ 0.34144279,  0.94630077]]])\n",
    "\n",
    "vectorized_image = image2vector(image)\n",
    "\n",
    "print (\"image2vector(image) = \" + str(vectorized_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Implement `vector2image()` that takes the above vector and reshape it back to an image, but this time of the shape (length\\*height ,depth)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector2image(vec, shape):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    vec -- a flattened image vector of shape (length*height*depth, 1)\n",
    "    shape -- a array indicating desired shape\n",
    "    \n",
    "    Returns:\n",
    "    v -- a vector of shape (length*height*depth, 1)\n",
    "    \"\"\"\n",
    "    image = vec.reshape((shape[0] * shape[1], shape[2]))\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector2image(vectorized_image ) = [[0.67826139 0.29380381]\n",
      " [0.90714982 0.52835647]\n",
      " [0.4215251  0.45017551]\n",
      " [0.92814219 0.96677647]\n",
      " [0.85304703 0.52351845]\n",
      " [0.19981397 0.27417313]\n",
      " [0.60659855 0.00533165]\n",
      " [0.10820313 0.49978937]\n",
      " [0.34144279 0.94630077]]\n"
     ]
    }
   ],
   "source": [
    "# call the function, fill in the right shape\n",
    "\n",
    "image_new = vector2image(vectorized_image, shape = [3, 3, 2])\n",
    "print (\"vector2image(vectorized_image ) = \" + str(image_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II Logistic Regression with a Neural Network mindset\n",
    "\n",
    "This assignment will step you through how to do this with a Neural Network mindset, and so will also hone your intuitions about deep learning.\n",
    "\n",
    "**Instructions:**\n",
    "- Do not use loops (for/while) in your code, unless the instructions explicitly ask you to do so.\n",
    "\n",
    "\n",
    "Implement  a gradient descent algorithm for logistic regression. This data are taken from a larger dataset, described in a South African Medical Journal.\n",
    "\n",
    "**Dataset: Use the following dataset for the implementation.**\n",
    "\n",
    "The full data is available at: http://statweb.stanford.edu/~tibs/ElemStatLearn/datasets/ For this project, you can use those located under in the folder. \n",
    "\n",
    "\n",
    "#### Description\n",
    "A retrospective sample of males in a heart-disease high-risk region of South Africa. There are roughly two controls per case of CHD. Many of the CHD positive men have undergone blood pressure reduction treatment and other programs to reduce their risk factors after their CHD event. In some cases, the measurements were made after these treatments.\n",
    " \n",
    "### Steps to implement\n",
    "\n",
    "*\tEncode the categorical variables.\n",
    "*\tNormalize the numerical variables\n",
    "*\tRandomly initialize beta values\n",
    "*\tDefine a sigmoid function to predict Y\n",
    "* Define a function for calculating binary cross entropy loss function \n",
    "* Define a function for updating beta values. The derivative term is same as derivative term for the linear regression as discussed in the class.\n",
    "* Write the code for gradient descent iterations.\n",
    "* Plot the cost function for different alpha (learning parameters) values.\n",
    "* Use sklearn logistic regression API and compare the estimation of beta values.\n",
    "\n",
    "\n",
    "### Important! \n",
    "\n",
    "Read the codes and comments carefully. You may need to fill in the code when you see \"################finish the code below##################\" in the comment line. Do not miss them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Packages ##\n",
    "\n",
    "\n",
    "If you don't have those packages, try pip/conda install *-insert package name-*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Overview of the Problem set ##\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load SAHeart csv file\n",
    "path1 = r\"path/SAHeart.csv\" #运行时需更新为实际本地路径\n",
    "SAHeart_df = pd.read_csv(path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row.names</th>\n",
       "      <th>sbp</th>\n",
       "      <th>tobacco</th>\n",
       "      <th>ldl</th>\n",
       "      <th>adiposity</th>\n",
       "      <th>famhist</th>\n",
       "      <th>typea</th>\n",
       "      <th>obesity</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>age</th>\n",
       "      <th>chd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>12.00</td>\n",
       "      <td>5.73</td>\n",
       "      <td>23.11</td>\n",
       "      <td>Present</td>\n",
       "      <td>49</td>\n",
       "      <td>25.30</td>\n",
       "      <td>97.20</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>144</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4.41</td>\n",
       "      <td>28.61</td>\n",
       "      <td>Absent</td>\n",
       "      <td>55</td>\n",
       "      <td>28.87</td>\n",
       "      <td>2.06</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>118</td>\n",
       "      <td>0.08</td>\n",
       "      <td>3.48</td>\n",
       "      <td>32.28</td>\n",
       "      <td>Present</td>\n",
       "      <td>52</td>\n",
       "      <td>29.14</td>\n",
       "      <td>3.81</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>170</td>\n",
       "      <td>7.50</td>\n",
       "      <td>6.41</td>\n",
       "      <td>38.03</td>\n",
       "      <td>Present</td>\n",
       "      <td>51</td>\n",
       "      <td>31.99</td>\n",
       "      <td>24.26</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>134</td>\n",
       "      <td>13.60</td>\n",
       "      <td>3.50</td>\n",
       "      <td>27.78</td>\n",
       "      <td>Present</td>\n",
       "      <td>60</td>\n",
       "      <td>25.99</td>\n",
       "      <td>57.34</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>132</td>\n",
       "      <td>6.20</td>\n",
       "      <td>6.47</td>\n",
       "      <td>36.21</td>\n",
       "      <td>Present</td>\n",
       "      <td>62</td>\n",
       "      <td>30.77</td>\n",
       "      <td>14.14</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>142</td>\n",
       "      <td>4.05</td>\n",
       "      <td>3.38</td>\n",
       "      <td>16.20</td>\n",
       "      <td>Absent</td>\n",
       "      <td>59</td>\n",
       "      <td>20.81</td>\n",
       "      <td>2.62</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>114</td>\n",
       "      <td>4.08</td>\n",
       "      <td>4.59</td>\n",
       "      <td>14.60</td>\n",
       "      <td>Present</td>\n",
       "      <td>62</td>\n",
       "      <td>23.11</td>\n",
       "      <td>6.72</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>114</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.83</td>\n",
       "      <td>19.40</td>\n",
       "      <td>Present</td>\n",
       "      <td>49</td>\n",
       "      <td>24.86</td>\n",
       "      <td>2.49</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>132</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.80</td>\n",
       "      <td>30.96</td>\n",
       "      <td>Present</td>\n",
       "      <td>69</td>\n",
       "      <td>30.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row.names  sbp  tobacco   ldl  adiposity  famhist  typea  obesity  alcohol  \\\n",
       "0          1  160    12.00  5.73      23.11  Present     49    25.30    97.20   \n",
       "1          2  144     0.01  4.41      28.61   Absent     55    28.87     2.06   \n",
       "2          3  118     0.08  3.48      32.28  Present     52    29.14     3.81   \n",
       "3          4  170     7.50  6.41      38.03  Present     51    31.99    24.26   \n",
       "4          5  134    13.60  3.50      27.78  Present     60    25.99    57.34   \n",
       "5          6  132     6.20  6.47      36.21  Present     62    30.77    14.14   \n",
       "6          7  142     4.05  3.38      16.20   Absent     59    20.81     2.62   \n",
       "7          8  114     4.08  4.59      14.60  Present     62    23.11     6.72   \n",
       "8          9  114     0.00  3.83      19.40  Present     49    24.86     2.49   \n",
       "9         10  132     0.00  5.80      30.96  Present     69    30.11     0.00   \n",
       "\n",
       "   age  chd  \n",
       "0   52    1  \n",
       "1   63    1  \n",
       "2   46    0  \n",
       "3   58    1  \n",
       "4   49    1  \n",
       "5   45    0  \n",
       "6   38    0  \n",
       "7   58    1  \n",
       "8   29    0  \n",
       "9   53    1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAHeart_df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Process variables ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert 'famhis' to dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAHeart_df['famhist']= pd.get_dummies(SAHeart_df['famhist'],drop_first = \"true\", dtype='uint8')\n",
    "\n",
    "# 和checkpoint作比较后加了unit8, 否则输出bool值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row.names</th>\n",
       "      <th>sbp</th>\n",
       "      <th>tobacco</th>\n",
       "      <th>ldl</th>\n",
       "      <th>adiposity</th>\n",
       "      <th>famhist</th>\n",
       "      <th>typea</th>\n",
       "      <th>obesity</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>age</th>\n",
       "      <th>chd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>12.00</td>\n",
       "      <td>5.73</td>\n",
       "      <td>23.11</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>25.30</td>\n",
       "      <td>97.20</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>144</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4.41</td>\n",
       "      <td>28.61</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>28.87</td>\n",
       "      <td>2.06</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>118</td>\n",
       "      <td>0.08</td>\n",
       "      <td>3.48</td>\n",
       "      <td>32.28</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>29.14</td>\n",
       "      <td>3.81</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>170</td>\n",
       "      <td>7.50</td>\n",
       "      <td>6.41</td>\n",
       "      <td>38.03</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>31.99</td>\n",
       "      <td>24.26</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>134</td>\n",
       "      <td>13.60</td>\n",
       "      <td>3.50</td>\n",
       "      <td>27.78</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>25.99</td>\n",
       "      <td>57.34</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>132</td>\n",
       "      <td>6.20</td>\n",
       "      <td>6.47</td>\n",
       "      <td>36.21</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>30.77</td>\n",
       "      <td>14.14</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>142</td>\n",
       "      <td>4.05</td>\n",
       "      <td>3.38</td>\n",
       "      <td>16.20</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>20.81</td>\n",
       "      <td>2.62</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>114</td>\n",
       "      <td>4.08</td>\n",
       "      <td>4.59</td>\n",
       "      <td>14.60</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>23.11</td>\n",
       "      <td>6.72</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>114</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.83</td>\n",
       "      <td>19.40</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>24.86</td>\n",
       "      <td>2.49</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>132</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.80</td>\n",
       "      <td>30.96</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>30.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row.names  sbp  tobacco   ldl  adiposity  famhist  typea  obesity  alcohol  \\\n",
       "0          1  160    12.00  5.73      23.11        1     49    25.30    97.20   \n",
       "1          2  144     0.01  4.41      28.61        0     55    28.87     2.06   \n",
       "2          3  118     0.08  3.48      32.28        1     52    29.14     3.81   \n",
       "3          4  170     7.50  6.41      38.03        1     51    31.99    24.26   \n",
       "4          5  134    13.60  3.50      27.78        1     60    25.99    57.34   \n",
       "5          6  132     6.20  6.47      36.21        1     62    30.77    14.14   \n",
       "6          7  142     4.05  3.38      16.20        0     59    20.81     2.62   \n",
       "7          8  114     4.08  4.59      14.60        1     62    23.11     6.72   \n",
       "8          9  114     0.00  3.83      19.40        1     49    24.86     2.49   \n",
       "9         10  132     0.00  5.80      30.96        1     69    30.11     0.00   \n",
       "\n",
       "   age  chd  \n",
       "0   52    1  \n",
       "1   63    1  \n",
       "2   46    0  \n",
       "3   58    1  \n",
       "4   49    1  \n",
       "5   45    0  \n",
       "6   38    0  \n",
       "7   58    1  \n",
       "8   29    0  \n",
       "9   53    1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAHeart_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (SAHeart_df[['famhist','sbp','tobacco','ldl','adiposity','typea','obesity','alcohol','age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>famhist</th>\n",
       "      <th>sbp</th>\n",
       "      <th>tobacco</th>\n",
       "      <th>ldl</th>\n",
       "      <th>adiposity</th>\n",
       "      <th>typea</th>\n",
       "      <th>obesity</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>12.00</td>\n",
       "      <td>5.73</td>\n",
       "      <td>23.11</td>\n",
       "      <td>49</td>\n",
       "      <td>25.30</td>\n",
       "      <td>97.20</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4.41</td>\n",
       "      <td>28.61</td>\n",
       "      <td>55</td>\n",
       "      <td>28.87</td>\n",
       "      <td>2.06</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>0.08</td>\n",
       "      <td>3.48</td>\n",
       "      <td>32.28</td>\n",
       "      <td>52</td>\n",
       "      <td>29.14</td>\n",
       "      <td>3.81</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>170</td>\n",
       "      <td>7.50</td>\n",
       "      <td>6.41</td>\n",
       "      <td>38.03</td>\n",
       "      <td>51</td>\n",
       "      <td>31.99</td>\n",
       "      <td>24.26</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>134</td>\n",
       "      <td>13.60</td>\n",
       "      <td>3.50</td>\n",
       "      <td>27.78</td>\n",
       "      <td>60</td>\n",
       "      <td>25.99</td>\n",
       "      <td>57.34</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   famhist  sbp  tobacco   ldl  adiposity  typea  obesity  alcohol  age\n",
       "0        1  160    12.00  5.73      23.11     49    25.30    97.20   52\n",
       "1        0  144     0.01  4.41      28.61     55    28.87     2.06   63\n",
       "2        1  118     0.08  3.48      32.28     52    29.14     3.81   46\n",
       "3        1  170     7.50  6.41      38.03     51    31.99    24.26   58\n",
       "4        1  134    13.60  3.50      27.78     60    25.99    57.34   49"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array(SAHeart_df[['chd']])\n",
    "#Y = (SAHeart_df[['chd']])\n",
    "#print(len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sbp</th>\n",
       "      <th>tobacco</th>\n",
       "      <th>ldl</th>\n",
       "      <th>adiposity</th>\n",
       "      <th>typea</th>\n",
       "      <th>obesity</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>160</td>\n",
       "      <td>12.00</td>\n",
       "      <td>5.73</td>\n",
       "      <td>23.11</td>\n",
       "      <td>49</td>\n",
       "      <td>25.30</td>\n",
       "      <td>97.20</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4.41</td>\n",
       "      <td>28.61</td>\n",
       "      <td>55</td>\n",
       "      <td>28.87</td>\n",
       "      <td>2.06</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>118</td>\n",
       "      <td>0.08</td>\n",
       "      <td>3.48</td>\n",
       "      <td>32.28</td>\n",
       "      <td>52</td>\n",
       "      <td>29.14</td>\n",
       "      <td>3.81</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>170</td>\n",
       "      <td>7.50</td>\n",
       "      <td>6.41</td>\n",
       "      <td>38.03</td>\n",
       "      <td>51</td>\n",
       "      <td>31.99</td>\n",
       "      <td>24.26</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>134</td>\n",
       "      <td>13.60</td>\n",
       "      <td>3.50</td>\n",
       "      <td>27.78</td>\n",
       "      <td>60</td>\n",
       "      <td>25.99</td>\n",
       "      <td>57.34</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>132</td>\n",
       "      <td>6.20</td>\n",
       "      <td>6.47</td>\n",
       "      <td>36.21</td>\n",
       "      <td>62</td>\n",
       "      <td>30.77</td>\n",
       "      <td>14.14</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>142</td>\n",
       "      <td>4.05</td>\n",
       "      <td>3.38</td>\n",
       "      <td>16.20</td>\n",
       "      <td>59</td>\n",
       "      <td>20.81</td>\n",
       "      <td>2.62</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>114</td>\n",
       "      <td>4.08</td>\n",
       "      <td>4.59</td>\n",
       "      <td>14.60</td>\n",
       "      <td>62</td>\n",
       "      <td>23.11</td>\n",
       "      <td>6.72</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>114</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.83</td>\n",
       "      <td>19.40</td>\n",
       "      <td>49</td>\n",
       "      <td>24.86</td>\n",
       "      <td>2.49</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>132</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.80</td>\n",
       "      <td>30.96</td>\n",
       "      <td>69</td>\n",
       "      <td>30.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sbp  tobacco   ldl  adiposity  typea  obesity  alcohol  age\n",
       "0  160    12.00  5.73      23.11     49    25.30    97.20   52\n",
       "1  144     0.01  4.41      28.61     55    28.87     2.06   63\n",
       "2  118     0.08  3.48      32.28     52    29.14     3.81   46\n",
       "3  170     7.50  6.41      38.03     51    31.99    24.26   58\n",
       "4  134    13.60  3.50      27.78     60    25.99    57.34   49\n",
       "5  132     6.20  6.47      36.21     62    30.77    14.14   45\n",
       "6  142     4.05  3.38      16.20     59    20.81     2.62   38\n",
       "7  114     4.08  4.59      14.60     62    23.11     6.72   58\n",
       "8  114     0.00  3.83      19.40     49    24.86     2.49   29\n",
       "9  132     0.00  5.80      30.96     69    30.11     0.00   53"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_Normal = ['sbp','tobacco','ldl','adiposity','typea','obesity','alcohol','age']\n",
    "\n",
    "X_new= X[cols_to_Normal]\n",
    "X_new.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalise the dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_new[cols_to_Normal].apply( lambda rec:(rec - rec.mean())/rec.std(), axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new['famhist'] = SAHeart_df['famhist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sbp</th>\n",
       "      <th>tobacco</th>\n",
       "      <th>ldl</th>\n",
       "      <th>adiposity</th>\n",
       "      <th>typea</th>\n",
       "      <th>obesity</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>age</th>\n",
       "      <th>famhist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.057417</td>\n",
       "      <td>1.821099</td>\n",
       "      <td>0.477894</td>\n",
       "      <td>-0.295183</td>\n",
       "      <td>-0.418017</td>\n",
       "      <td>-0.176594</td>\n",
       "      <td>3.274189</td>\n",
       "      <td>0.628654</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.276789</td>\n",
       "      <td>-0.789382</td>\n",
       "      <td>-0.159507</td>\n",
       "      <td>0.411694</td>\n",
       "      <td>0.193134</td>\n",
       "      <td>0.670646</td>\n",
       "      <td>-0.612081</td>\n",
       "      <td>1.381617</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.991731</td>\n",
       "      <td>-0.774141</td>\n",
       "      <td>-0.608585</td>\n",
       "      <td>0.883374</td>\n",
       "      <td>-0.112441</td>\n",
       "      <td>0.734723</td>\n",
       "      <td>-0.540597</td>\n",
       "      <td>0.217947</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.545310</td>\n",
       "      <td>0.841352</td>\n",
       "      <td>0.806252</td>\n",
       "      <td>1.622382</td>\n",
       "      <td>-0.214300</td>\n",
       "      <td>1.411091</td>\n",
       "      <td>0.294742</td>\n",
       "      <td>1.039361</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.211103</td>\n",
       "      <td>2.169453</td>\n",
       "      <td>-0.598928</td>\n",
       "      <td>0.305020</td>\n",
       "      <td>0.702427</td>\n",
       "      <td>-0.012842</td>\n",
       "      <td>1.645991</td>\n",
       "      <td>0.423301</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.308682</td>\n",
       "      <td>0.558314</td>\n",
       "      <td>0.835225</td>\n",
       "      <td>1.388470</td>\n",
       "      <td>0.906144</td>\n",
       "      <td>1.121558</td>\n",
       "      <td>-0.118638</td>\n",
       "      <td>0.149496</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.179211</td>\n",
       "      <td>0.090213</td>\n",
       "      <td>-0.656873</td>\n",
       "      <td>-1.183278</td>\n",
       "      <td>0.600569</td>\n",
       "      <td>-1.242171</td>\n",
       "      <td>-0.589206</td>\n",
       "      <td>-0.329662</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.186888</td>\n",
       "      <td>0.096745</td>\n",
       "      <td>-0.072589</td>\n",
       "      <td>-1.388915</td>\n",
       "      <td>0.906144</td>\n",
       "      <td>-0.696330</td>\n",
       "      <td>-0.421730</td>\n",
       "      <td>1.039361</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.186888</td>\n",
       "      <td>-0.791559</td>\n",
       "      <td>-0.439577</td>\n",
       "      <td>-0.772004</td>\n",
       "      <td>-0.418017</td>\n",
       "      <td>-0.281016</td>\n",
       "      <td>-0.594517</td>\n",
       "      <td>-0.945722</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.308682</td>\n",
       "      <td>-0.791559</td>\n",
       "      <td>0.511696</td>\n",
       "      <td>0.713724</td>\n",
       "      <td>1.619154</td>\n",
       "      <td>0.964925</td>\n",
       "      <td>-0.696228</td>\n",
       "      <td>0.697105</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sbp   tobacco       ldl  adiposity     typea   obesity   alcohol  \\\n",
       "0  1.057417  1.821099  0.477894  -0.295183 -0.418017 -0.176594  3.274189   \n",
       "1  0.276789 -0.789382 -0.159507   0.411694  0.193134  0.670646 -0.612081   \n",
       "2 -0.991731 -0.774141 -0.608585   0.883374 -0.112441  0.734723 -0.540597   \n",
       "3  1.545310  0.841352  0.806252   1.622382 -0.214300  1.411091  0.294742   \n",
       "4 -0.211103  2.169453 -0.598928   0.305020  0.702427 -0.012842  1.645991   \n",
       "5 -0.308682  0.558314  0.835225   1.388470  0.906144  1.121558 -0.118638   \n",
       "6  0.179211  0.090213 -0.656873  -1.183278  0.600569 -1.242171 -0.589206   \n",
       "7 -1.186888  0.096745 -0.072589  -1.388915  0.906144 -0.696330 -0.421730   \n",
       "8 -1.186888 -0.791559 -0.439577  -0.772004 -0.418017 -0.281016 -0.594517   \n",
       "9 -0.308682 -0.791559  0.511696   0.713724  1.619154  0.964925 -0.696228   \n",
       "\n",
       "        age  famhist  \n",
       "0  0.628654        1  \n",
       "1  1.381617        0  \n",
       "2  0.217947        1  \n",
       "3  1.039361        1  \n",
       "4  0.423301        1  \n",
       "5  0.149496        1  \n",
       "6 -0.329662        0  \n",
       "7  1.039361        1  \n",
       "8 -0.945722        1  \n",
       "9  0.697105        1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sbp',\n",
       " 'tobacco',\n",
       " 'ldl',\n",
       " 'adiposity',\n",
       " 'typea',\n",
       " 'obesity',\n",
       " 'alcohol',\n",
       " 'age',\n",
       " 'famhist']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.05741729,  1.8210988 ,  0.47789413, -0.29518321, -0.41801699,\n",
       "        -0.17659445,  3.27418871,  0.62865426,  1.        ],\n",
       "       [ 0.27678925, -0.78938174, -0.15950708,  0.41169419,  0.19313443,\n",
       "         0.67064592, -0.61208112,  1.38161701,  0.        ],\n",
       "       [-0.99173133, -0.77414124, -0.6085852 ,  0.8833742 , -0.11244128,\n",
       "         0.73472292, -0.54059729,  0.2179473 ,  1.        ],\n",
       "       [ 1.54530982,  0.84135214,  0.80625232,  1.62238239, -0.21429985,\n",
       "         1.41109128,  0.2947424 ,  1.03936121,  1.        ],\n",
       "       [-0.21110328,  2.16945317, -0.59892761,  0.30501996,  0.70242729,\n",
       "        -0.01284211,  1.64599115,  0.42330078,  1.        ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = np.array(X_new)\n",
    "X_new[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4- Randomly Initialising values of beta coefficient ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_betas(dim):\n",
    "    b = random.random()\n",
    "    w = np.random.rand(dim)\n",
    "    return b,w \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4620291418562038 [0.29560011 0.73996583 0.90963315 0.54134988 0.05951375 0.35888926\n",
      " 0.77794304 0.76841869 0.29892462]\n"
     ]
    }
   ],
   "source": [
    "b,w = initialize_betas(X_new.shape[1])\n",
    "print(b,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5- Define a sigmoid function to predict Y ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(b, w ,X_new):\n",
    "    '''\n",
    "    Z= wx+b\n",
    "    '''\n",
    "    \n",
    "    ##############finish the code here#####################\n",
    "    Z = np.dot(X_new, w) + b\n",
    "    Sigmoid_Z = 1 / (1 + np.exp(-Z))\n",
    "    return  Sigmoid_Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99645242, 0.70582408, 0.45598877, 0.99312946, 0.97253906])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = sigmoid(b,w,X_new)\n",
    "\n",
    "y_hat[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Y[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1]], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6- Define a function for calculating binary cross entropy loss function ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cost( y, y_hat):\n",
    "    \n",
    "    '''\n",
    "    Input: y: a vector of true labels, y_hat: a vector of predicted outcome from logistic regression\n",
    "    Return: the value of cost or loss function\n",
    "    Loss function L = -1/m\\Sigma (y log y_hat + (1-y)log 1-y_hat)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    ### finish the code here\n",
    "    m = len(y)\n",
    "    loss = - (1/m) * np.sum(y * np.log(y_hat) + (1 - y) * np.log(1 - y_hat))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((462,), (462,))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape Y\n",
    "Y=Y.reshape(len(Y), )\n",
    "current_cost= get_cost(Y,y_hat)\n",
    "#print(current_cost)\n",
    "Y.shape, y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(462, 9)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7- Define a function for updating w and b using backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write backpropagation function here\n",
    "\n",
    "def backprop (b_0, w_0 , y , y_hat, X_new, alpha = 0.1):\n",
    "    '''\n",
    "    Input: weight to be updated b_0, and w_0, as well as y and y_hat to calculate dz (defined as dL/dz)\n",
    "    output: new updated b_0 and w_0\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    dz = y_hat-y\n",
    "    ########finish the code here, to calculate db defined as dL/db\n",
    "\n",
    "    m = X_new.shape[0]\n",
    "    \n",
    "    db = (1 / m) * np.sum(dz)\n",
    "    \n",
    "    # update b_0\n",
    "    b_0 = b_0 - alpha * db\n",
    "    \n",
    "    \n",
    "    ########finish the code here, , to calculate db defined as dL/db\n",
    "    dw = (1 / m) * np.dot(X_new.T, dz)\n",
    "    \n",
    "    #update w_0\n",
    "    w_0 = w_0 - alpha * dw\n",
    "   \n",
    "   \n",
    "    return b_0,w_0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(462, 9)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 0.1\n",
    "\n",
    "type(y_hat)\n",
    "#(X_new).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b,w = backprop (b, w, Y, y_hat,X_new, alpha)\n",
    "\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.2628591785443852"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.13328196,  0.36452443,  0.36025155,  0.14387359,  0.38868162,\n",
       "       -0.26453297,  0.00302582,  0.66106879,  0.92492791])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(b,w)\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  8- Finally, let's try the gradient descent!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial guess of b and w:  0.10068278504311678 [0.16161311 0.13577227 0.31933617 0.12745551 0.66799098 0.15746881\n",
      " 0.60328091 0.11376943 0.20606248]\n"
     ]
    }
   ],
   "source": [
    "num_iterations = 500\n",
    "alpha = 0.5\n",
    "\n",
    "all_costs = []\n",
    "b,w = initialize_betas(X_new.shape[1])\n",
    "print(\"initial guess of b and w: \" , b ,w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0 Cost:  0.6986445297937693\n",
      "Iteration:  10 Cost:  0.5491971175942864\n",
      "Iteration:  20 Cost:  0.5275723390382866\n",
      "Iteration:  30 Cost:  0.5212475375721342\n",
      "Iteration:  40 Cost:  0.5179315160620384\n",
      "Iteration:  50 Cost:  0.5158222718685285\n",
      "Iteration:  60 Cost:  0.514396633014354\n",
      "Iteration:  70 Cost:  0.5134085456397346\n",
      "Iteration:  80 Cost:  0.5127144464850214\n",
      "Iteration:  90 Cost:  0.5122227452684441\n",
      "Iteration:  100 Cost:  0.5118724177266623\n",
      "Iteration:  110 Cost:  0.5116217787120777\n",
      "Iteration:  120 Cost:  0.5114418980341733\n",
      "Iteration:  130 Cost:  0.5113124814375866\n",
      "Iteration:  140 Cost:  0.511219185062426\n",
      "Iteration:  150 Cost:  0.511151814964303\n",
      "Iteration:  160 Cost:  0.511103096444111\n",
      "Iteration:  170 Cost:  0.5110678213119274\n",
      "Iteration:  180 Cost:  0.511042251207359\n",
      "Iteration:  190 Cost:  0.5110236970701383\n",
      "Iteration:  200 Cost:  0.5110102211412377\n",
      "Iteration:  210 Cost:  0.5110004248982557\n",
      "Iteration:  220 Cost:  0.5109932976344964\n",
      "Iteration:  230 Cost:  0.5109881080412687\n",
      "Iteration:  240 Cost:  0.5109843264018586\n",
      "Iteration:  250 Cost:  0.5109815686448157\n",
      "Iteration:  260 Cost:  0.5109795560474685\n",
      "Iteration:  270 Cost:  0.5109780861690795\n",
      "Iteration:  280 Cost:  0.5109770118570071\n",
      "Iteration:  290 Cost:  0.5109762260661441\n",
      "Iteration:  300 Cost:  0.5109756508704815\n",
      "Iteration:  310 Cost:  0.5109752295016083\n",
      "Iteration:  320 Cost:  0.5109749205753111\n",
      "Iteration:  330 Cost:  0.5109746939015282\n",
      "Iteration:  340 Cost:  0.5109745274411186\n",
      "Iteration:  350 Cost:  0.5109744050939746\n",
      "Iteration:  360 Cost:  0.5109743150902647\n",
      "Iteration:  370 Cost:  0.5109742488195657\n",
      "Iteration:  380 Cost:  0.5109741999781368\n",
      "Iteration:  390 Cost:  0.5109741639474921\n",
      "Iteration:  400 Cost:  0.5109741373412383\n",
      "Iteration:  410 Cost:  0.5109741176744048\n",
      "Iteration:  420 Cost:  0.5109741031219962\n",
      "Iteration:  430 Cost:  0.5109740923425776\n",
      "Iteration:  440 Cost:  0.5109740843492873\n",
      "Iteration:  450 Cost:  0.5109740784154613\n",
      "Iteration:  460 Cost:  0.5109740740055344\n",
      "Iteration:  470 Cost:  0.5109740707244083\n",
      "Iteration:  480 Cost:  0.5109740682803241\n",
      "Iteration:  490 Cost:  0.5109740664576178\n",
      "Final estimates of b and w are:  -1.2629006164767618 [ 0.13329264  0.36454653  0.36020717  0.14436291  0.38870369 -0.26488916\n",
      "  0.00300182  0.6608223   0.9250172 ]\n"
     ]
    }
   ],
   "source": [
    "for each_iter in range (num_iterations ):\n",
    "    ###### finish the code below\n",
    "    y_hat = sigmoid(b, w, X_new)\n",
    "    current_cost = get_cost(Y, y_hat)\n",
    "    prev_b = b\n",
    "    prev_w = w\n",
    "    b, w = backprop(b, w, Y, y_hat, X_new, alpha)\n",
    "    all_costs.append(current_cost)\n",
    "    if each_iter % 10 == 0:\n",
    "        print('Iteration: ', each_iter, 'Cost: ', current_cost)\n",
    "        each_iter += 1\n",
    "    \n",
    "#print('b_0:', b_0, 'b_1:',b_1,'b_2:',b_2,'b_3:',b_3,'b_4:', b_4, 'b_5:',b_5,'b_6:',b_6,'b_7:',b_7,'b_8:',b_8,'b_9:',b_9)\n",
    "# print(\"Final estimates of b and q are: \", b,w) ←我觉得这个q不对，应该是w\n",
    "print(\"Final estimates of b and w are: \", b,w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9- Let's validate our result against sklearn logistic regression API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lreg = LogisticRegression()\n",
    "lmodel = lreg.fit(X_new, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.23623307])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmodel.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.13249594,  0.36074563,  0.35615923,  0.14242442,  0.37964323,\n",
       "        -0.25524232,  0.00443547,  0.64963333,  0.88060142]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmodel.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10- Visualization using matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1f0d9f10fd0>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter( range(num_iterations), all_costs)\n",
    "\n",
    "#len(range(each_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent is converging correctly for 500 iterations and with learning rate =0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11- Tuning learning rate alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current learning rate is 0.01\n",
      "initial guess of b and w:  0.9620432357360591 [0.38220595 0.0477295  0.19476365 0.86807253 0.64828036 0.17327088\n",
      " 0.5069513  0.09935706 0.46548836]\n",
      "Iteration:  0 Cost:  0.996725800733059\n",
      "Iteration:  30 Cost:  0.9501133159729248\n",
      "Iteration:  60 Cost:  0.9068080160197557\n",
      "Iteration:  90 Cost:  0.8668007887694986\n",
      "Iteration:  120 Cost:  0.8300581754315028\n",
      "Iteration:  150 Cost:  0.7965187696857765\n",
      "Iteration:  180 Cost:  0.766091174531342\n",
      "Iteration:  210 Cost:  0.7386538729041888\n",
      "Iteration:  240 Cost:  0.7140571873811487\n",
      "Iteration:  270 Cost:  0.6921272409028938\n",
      "Iteration:  300 Cost:  0.6726715382507835\n",
      "Iteration:  330 Cost:  0.6554855481137735\n",
      "Iteration:  360 Cost:  0.6403595515572412\n",
      "Iteration:  390 Cost:  0.6270850637873879\n",
      "Iteration:  420 Cost:  0.615460304557988\n",
      "Iteration:  450 Cost:  0.6052944227070075\n",
      "Iteration:  480 Cost:  0.5964104028506418\n",
      "Iteration:  510 Cost:  0.5886467509613496\n",
      "Iteration:  540 Cost:  0.5818581549260747\n",
      "Iteration:  570 Cost:  0.5759153539907398\n",
      "Iteration:  600 Cost:  0.5707044456625864\n",
      "Iteration:  630 Cost:  0.5661258291656701\n",
      "Iteration:  660 Cost:  0.5620929455050746\n",
      "Iteration:  690 Cost:  0.5585309347562106\n",
      "Iteration:  720 Cost:  0.5553752961239702\n",
      "Iteration:  750 Cost:  0.5525706074780967\n",
      "Iteration:  780 Cost:  0.5500693386774844\n",
      "Iteration:  810 Cost:  0.547830776436676\n",
      "Iteration:  840 Cost:  0.5458200668196896\n",
      "Iteration:  870 Cost:  0.5440073736615796\n",
      "Iteration:  900 Cost:  0.5423671463805345\n",
      "Iteration:  930 Cost:  0.540877487950213\n",
      "Iteration:  960 Cost:  0.5395196126035069\n",
      "Iteration:  990 Cost:  0.5382773826326938\n",
      "Final estimates of b and w are:  -0.5846611642218428 [ 0.17895512  0.31858672  0.27768127  0.43396753  0.37457705 -0.33803928\n",
      "  0.06538291  0.33831014  0.14040385]\n",
      "current learning rate is 0.001\n",
      "initial guess of b and w:  0.9301261420388658 [0.82615961 0.58881996 0.02627685 0.2770534  0.29799606 0.65119227\n",
      " 0.75785517 0.18888325 0.28113564]\n",
      "Iteration:  0 Cost:  1.0039007638441768\n",
      "Iteration:  30 Cost:  0.9996135121889411\n",
      "Iteration:  60 Cost:  0.9953533165704557\n",
      "Iteration:  90 Cost:  0.9911201794978578\n",
      "Iteration:  120 Cost:  0.9869141016031613\n",
      "Iteration:  150 Cost:  0.9827350816412991\n",
      "Iteration:  180 Cost:  0.978583116490466\n",
      "Iteration:  210 Cost:  0.9744582011527656\n",
      "Iteration:  240 Cost:  0.9703603287551459\n",
      "Iteration:  270 Cost:  0.9662894905506155\n",
      "Iteration:  300 Cost:  0.9622456759197349\n",
      "Iteration:  330 Cost:  0.9582288723723721\n",
      "Iteration:  360 Cost:  0.9542390655497202\n",
      "Iteration:  390 Cost:  0.9502762392265653\n",
      "Iteration:  420 Cost:  0.9463403753138027\n",
      "Iteration:  450 Cost:  0.9424314538611914\n",
      "Iteration:  480 Cost:  0.9385494530603502\n",
      "Iteration:  510 Cost:  0.9346943492479808\n",
      "Iteration:  540 Cost:  0.9308661169093218\n",
      "Iteration:  570 Cost:  0.9270647286818287\n",
      "Iteration:  600 Cost:  0.9232901553590747\n",
      "Iteration:  630 Cost:  0.919542365894875\n",
      "Iteration:  660 Cost:  0.9158213274076294\n",
      "Iteration:  690 Cost:  0.9121270051848852\n",
      "Iteration:  720 Cost:  0.9084593626881191\n",
      "Iteration:  750 Cost:  0.9048183615577395\n",
      "Iteration:  780 Cost:  0.9012039616183107\n",
      "Iteration:  810 Cost:  0.8976161208840004\n",
      "Iteration:  840 Cost:  0.8940547955642507\n",
      "Iteration:  870 Cost:  0.8905199400696835\n",
      "Iteration:  900 Cost:  0.8870115070182322\n",
      "Iteration:  930 Cost:  0.8835294472415146\n",
      "Iteration:  960 Cost:  0.880073709791445\n",
      "Iteration:  990 Cost:  0.8766442419470925\n",
      "Final estimates of b and w are:  0.6533049523406882 [0.74144872 0.578243   0.04563908 0.18885328 0.30765714 0.51902221\n",
      " 0.65397713 0.17884742 0.19348803]\n",
      "current learning rate is 0.0001\n",
      "initial guess of b and w:  0.5789970243001458 [0.53974588 0.56057752 0.16285592 0.15221465 0.88008088 0.50161368\n",
      " 0.66213983 0.30799777 0.83978003]\n",
      "Iteration:  0 Cost:  0.9172630622998735\n",
      "Iteration:  30 Cost:  0.9168775344643879\n",
      "Iteration:  60 Cost:  0.9164922703116767\n",
      "Iteration:  90 Cost:  0.9161072698136475\n",
      "Iteration:  120 Cost:  0.9157225329420687\n",
      "Iteration:  150 Cost:  0.9153380596685727\n",
      "Iteration:  180 Cost:  0.9149538499646533\n",
      "Iteration:  210 Cost:  0.9145699038016674\n",
      "Iteration:  240 Cost:  0.9141862211508327\n",
      "Iteration:  270 Cost:  0.9138028019832312\n",
      "Iteration:  300 Cost:  0.9134196462698059\n",
      "Iteration:  330 Cost:  0.913036753981362\n",
      "Iteration:  360 Cost:  0.9126541250885676\n",
      "Iteration:  390 Cost:  0.9122717595619523\n",
      "Iteration:  420 Cost:  0.9118896573719076\n",
      "Iteration:  450 Cost:  0.9115078184886879\n",
      "Iteration:  480 Cost:  0.9111262428824095\n",
      "Iteration:  510 Cost:  0.9107449305230498\n",
      "Iteration:  540 Cost:  0.9103638813804482\n",
      "Iteration:  570 Cost:  0.9099830954243077\n",
      "Iteration:  600 Cost:  0.9096025726241909\n",
      "Iteration:  630 Cost:  0.9092223129495244\n",
      "Iteration:  660 Cost:  0.9088423163695943\n",
      "Iteration:  690 Cost:  0.9084625828535511\n",
      "Iteration:  720 Cost:  0.9080831123704045\n",
      "Iteration:  750 Cost:  0.9077039048890277\n",
      "Iteration:  780 Cost:  0.9073249603781548\n",
      "Iteration:  810 Cost:  0.9069462788063813\n",
      "Iteration:  840 Cost:  0.9065678601421652\n",
      "Iteration:  870 Cost:  0.9061897043538253\n",
      "Iteration:  900 Cost:  0.9058118114095421\n",
      "Iteration:  930 Cost:  0.905434181277358\n",
      "Iteration:  960 Cost:  0.9050568139251762\n",
      "Iteration:  990 Cost:  0.9046797093207616\n",
      "Final estimates of b and w are:  0.550419723345858 [0.53477442 0.56020431 0.16334838 0.14544802 0.87319628 0.49030302\n",
      " 0.65285543 0.30793505 0.82874327]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "####plot the cost function for different alpha values, 0.01,0.001,0.0001\n",
    "\n",
    "# For alpha =0.01\n",
    "\n",
    "alphas = [0.01, 0.001, 0.0001]\n",
    "num_iterations = 1000\n",
    "colors = ['r', 'g', 'b']\n",
    "for i, alpha in enumerate(alphas):\n",
    "    print(f'current learning rate is {alpha}')\n",
    "\n",
    "    all_costs = []\n",
    "    b,w = initialize_betas(X_new.shape[1])\n",
    "    print(\"initial guess of b and w: \" , b ,w)\n",
    "\n",
    "    for each_iter in range (num_iterations ):\n",
    "        ################finish the code below##################\n",
    "        y_hat = sigmoid(b, w, X_new)\n",
    "        current_cost = get_cost(Y, y_hat)\n",
    "        prev_b = b\n",
    "        prev_w = w\n",
    "        \n",
    "        ################finish the code below##################\n",
    "        b, w =  backprop(b, w, Y, y_hat, X_new, alpha)\n",
    "        all_costs.append(current_cost)\n",
    "        if each_iter % 30 == 0:\n",
    "            print('Iteration: ', each_iter, 'Cost: ', current_cost)\n",
    "            each_iter += 1\n",
    "\n",
    "    #print('b_0:', b_0, 'b_1:',b_1,'b_2:',b_2,'b_3:',b_3,'b_4:', b_4, 'b_5:',b_5,'b_6:',b_6,'b_7:',b_7,'b_8:',b_8,'b_9:',b_9)\n",
    "    #print(\"Final estimates of b and q are: \", b,w) 感觉不是q，应该是w\n",
    "    print(\"Final estimates of b and w are: \", b,w)\n",
    "    plt.scatter( range(num_iterations), all_costs, c = colors[i], label = f'{alpha}')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the experiment above, which is the best choice for alpha? Why?\n",
    "\n",
    "**Answer Below**:  \n",
    "I think it should be the green line, whose alpha = 0.001.  \n",
    "\n",
    "Based on the experiment above, the best choice for the learning rate alpha should be 0.001 depending on the trade-off we want to achieve between convergence speed and stability during the model training process. Here's an analysis of the different learning rates and the recommended option:\n",
    "\n",
    "### Best Choice for Alpha and Why:\n",
    "\n",
    "1. **Learning Rate = 0.01 (Red Curve):**\n",
    "   - **Advantages:** This learning rate offers the fastest convergence speed, with large parameter updates that quickly reduce the cost value.\n",
    "   - **Disadvantages:** Due to the large update size, it may cause the model to oscillate around the optimal solution, sometimes failing to converge to the global optimum. Additionally, a learning rate that is too high can lead to instability during training.\n",
    "\n",
    "2. **Learning Rate = 0.001 (Green Curve):**\n",
    "   - **Advantages:** This learning rate provides a good compromise. It ensures the model converges at a reasonable speed while maintaining a certain level of stability, reducing oscillations around the minimum.\n",
    "   - **Disadvantages:** Compared to 0.01, its convergence speed is slower, requiring more iterations to reach a similar cost value.\n",
    "\n",
    "3. **Learning Rate = 0.0001 (Blue Curve):**\n",
    "   - **Advantages:** This learning rate provides the most stable training process, with a smooth decrease in cost and minimal oscillation.\n",
    "   - **Disadvantages:** The convergence speed is very slow, requiring a large number of iterations to reach cost values similar to those with other learning rates, potentially leading to low training efficiency.\n",
    "\n",
    "#### Recommended Learning Rate:\n",
    "\n",
    "Based on the experimental results, **0.001 (Green Curve)** might be a better choice. Here's why:\n",
    "\n",
    "- **Balanced Convergence Speed:** Although not as fast as 0.01, it can still reach a lower cost value in a reasonable amount of time.\n",
    "- **Stability:** Compared to 0.01, 0.001 offers a more stable training process, reducing oscillation and helping the model converge to a better solution.\n",
    "- **Avoids Excessively Slow Training:** While 0.0001 provides the most stable training process, its excessively slow convergence speed can result in inefficient training, whereas 0.001 offers a good balance between stability and speed.\n",
    "\n",
    "### Conclusion:\n",
    "\n",
    "Considering both convergence speed and training stability, **0.001** is a reasonable choice for the learning rate. It ensures stability in the model training process while providing acceptable convergence speed. Of course, the optimal learning rate can also depend on the specific problem and dataset characteristics, so further adjustments and optimizations might be needed in practical applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
